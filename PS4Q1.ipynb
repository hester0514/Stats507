{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind_from_stats\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm, binom, beta\n",
    "import math\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>martial_status</th>\n",
       "      <th>interview_status</th>\n",
       "      <th>maskedvar-psu</th>\n",
       "      <th>maskedvar-stra</th>\n",
       "      <th>fullsample2yr_mec</th>\n",
       "      <th>fullsample2yr_int</th>\n",
       "      <th>cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62161</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102641.41</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62162</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15457.74</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62163</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7397.68</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62164</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127351.37</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62165</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12209.74</td>\n",
       "      <td>2011-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9249</th>\n",
       "      <td>102952</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16896.28</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9250</th>\n",
       "      <td>102953</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61630.38</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9251</th>\n",
       "      <td>102954</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17160.90</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9252</th>\n",
       "      <td>102955</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14238.45</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9253</th>\n",
       "      <td>102956</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38645.74</td>\n",
       "      <td>2017-2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39156 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  age  race education martial_status interview_status  \\\n",
       "0      62161   22     3       3.0            5.0              2.0   \n",
       "1      62162    3     1       NaN            NaN              2.0   \n",
       "2      62163   14     6       NaN            NaN              2.0   \n",
       "3      62164   44     3       4.0            1.0              2.0   \n",
       "4      62165   14     4       NaN            NaN              2.0   \n",
       "...      ...  ...   ...       ...            ...              ...   \n",
       "9249  102952   70     6       3.0            1.0              2.0   \n",
       "9250  102953   42     1       3.0            4.0              2.0   \n",
       "9251  102954   41     4       5.0            5.0              2.0   \n",
       "9252  102955   14     4       NaN            NaN              2.0   \n",
       "9253  102956   38     3       4.0            3.0              2.0   \n",
       "\n",
       "      maskedvar-psu  maskedvar-stra  fullsample2yr_mec  fullsample2yr_int  \\\n",
       "0               1.0            91.0                NaN          102641.41   \n",
       "1               3.0            92.0                NaN           15457.74   \n",
       "2               3.0            90.0                NaN            7397.68   \n",
       "3               1.0            94.0                NaN          127351.37   \n",
       "4               2.0            90.0                NaN           12209.74   \n",
       "...             ...             ...                ...                ...   \n",
       "9249            2.0           138.0                NaN           16896.28   \n",
       "9250            2.0           137.0                NaN           61630.38   \n",
       "9251            1.0           144.0                NaN           17160.90   \n",
       "9252            1.0           136.0                NaN           14238.45   \n",
       "9253            1.0           142.0                NaN           38645.74   \n",
       "\n",
       "         cohort  \n",
       "0     2011-2012  \n",
       "1     2011-2012  \n",
       "2     2011-2012  \n",
       "3     2011-2012  \n",
       "4     2011-2012  \n",
       "...         ...  \n",
       "9249  2017-2018  \n",
       "9250  2017-2018  \n",
       "9251  2017-2018  \n",
       "9252  2017-2018  \n",
       "9253  2017-2018  \n",
       "\n",
       "[39156 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Datasets of demography\n",
    "demo11_12 = pd.read_sas('/Users/Sylvia/Desktop/DEMO_G.XPT', encoding = 'utf-8')\n",
    "demo13_14 = pd.read_sas('/Users/Sylvia/Desktop/DEMO_H.XPT', encoding = 'utf-8')\n",
    "demo15_16 = pd.read_sas('/Users/Sylvia/Desktop/DEMO_I.XPT', encoding = 'utf-8')\n",
    "demo17_18 = pd.read_sas('/Users/Sylvia/Desktop/DEMO_J.XPT', encoding = 'utf-8')\n",
    "\n",
    "#Extract columns\n",
    "updateddemo11_12 = demo11_12[['SEQN','RIDAGEYR','RIAGENDR','RIDRETH3','DMDEDUC2','DMDMARTL','RIDSTATR','SDMVPSU','SDMVSTRA',\n",
    "                             'WTMEC2YR','WTINT2YR']]\n",
    "updateddemo13_14 = demo13_14[['SEQN','RIDAGEYR','RIAGENDR','RIDRETH3','DMDEDUC2','DMDMARTL','RIDSTATR','SDMVPSU','SDMVSTRA',\n",
    "                             'WTMEC2YR','WTINT2YR']]\n",
    "updateddemo15_16 = demo15_16[['SEQN','RIDAGEYR','RIAGENDR','RIDRETH3','DMDEDUC2','DMDMARTL','RIDSTATR','SDMVPSU','SDMVSTRA',\n",
    "                             'WTMEC2YR','WTINT2YR']]\n",
    "updateddemo17_18 = demo17_18[['SEQN','RIDAGEYR','RIAGENDR','RIDRETH3','DMDEDUC2','DMDMARTL','RIDSTATR','SDMVPSU','SDMVSTRA',\n",
    "                             'WTMEC2YR','WTINT2YR']]\n",
    "\n",
    "#Create Cohorts\n",
    "updateddemo11_12['cohort'] = '2011-2012'\n",
    "updateddemo13_14['cohort'] = '2013-2014'\n",
    "updateddemo15_16['cohort'] = '2015-2016'\n",
    "updateddemo17_18['cohort'] = '2017-2018'\n",
    "\n",
    "#Clean data\n",
    "demo = pd.concat([updateddemo11_12, updateddemo13_14, updateddemo15_16, updateddemo17_18], axis = 0)\n",
    "demo = demo.rename(columns ={'SEQN':'id','RIDAGEYR':'age','RIAGENDR':'gender','RIDRETH3':'race',\n",
    "                             'DMDEDUC2':'education',\n",
    "                            'DMDMARTL':'martial_status','RIDSTATR':'exam_status','SDMVPSU':'maskedvar-psu',\n",
    "                            'SDMVSTRA':'maskedvar-stra','WTMEC2YR':'fullsample2yr_mec',\n",
    "                            'WTINT2YR':'fullsample2yr_int'})\n",
    "demo[['id','age','race']] = demo[['id','age','race']].astype(int)\n",
    "demo[['education', 'martial_status', 'exam_status']] = demo[['education', 'martial_status', 'exam_status']].astype('category')\n",
    "demo[['fullsample2yr_mec','fullsample2yr_int']] = demo[['fullsample2yr_mec','fullsample2yr_int']].round(2)\n",
    "demo['fullsample2yr_mec'] = pd.to_numeric(demo['fullsample2yr_mec'], errors='coerce')\n",
    "demo['maskedvar-psu'] = pd.to_numeric(demo['maskedvar-psu'], errors='coerce')\n",
    "demo['maskedvar-stra'] = pd.to_numeric(demo['maskedvar-stra'], errors='coerce')\n",
    "demo['cohort'] = demo['cohort'].astype('category')\n",
    "\n",
    "#Import datasets of oral health\n",
    "oral11_12 = pd.read_sas('/Users/Sylvia/Desktop/OHXDEN_G.XPT', encoding = 'utf-8')\n",
    "oral13_14 = pd.read_sas('/Users/Sylvia/Desktop/OHXDEN_H.XPT', encoding = 'utf-8')\n",
    "oral15_16 = pd.read_sas('/Users/Sylvia/Desktop/OHXDEN_I.XPT', encoding = 'utf-8')\n",
    "oral17_18 = pd.read_sas('/Users/Sylvia/Desktop/OHXDEN_J.XPT', encoding = 'utf-8')\n",
    "\n",
    "#Extract columns\n",
    "updatedoral11_12 = oral11_12[['SEQN','OHDDESTS']]\n",
    "updatedoral13_14 = oral13_14[['SEQN','OHDDESTS']]\n",
    "updatedoral15_16 = oral15_16[['SEQN','OHDDESTS']]\n",
    "updatedoral17_18 = oral17_18[['SEQN','OHDDESTS']]\n",
    "\n",
    "#Setup cohorts\n",
    "updatedoral11_12['cohort'] = '2011-2012'\n",
    "updatedoral13_14['cohort'] = '2013-2014'\n",
    "updatedoral15_16['cohort'] = '2015-2016'\n",
    "updatedoral17_18['cohort'] = '2017-2018'\n",
    "\n",
    "#Concat datasets\n",
    "oral = pd.concat([updatedoral11_12, updatedoral13_14, updatedoral15_16, updatedoral17_18], axis = 0)\n",
    "oral = oral.rename(columns = {'SEQN':'id', 'OHDDESTS':'ohx_status'})\n",
    "oral[['id','ohx_status']] = oral[['id','ohx_status']].astype(int)\n",
    "oral.iloc[:,2:] = oral.iloc[:,2:].astype('category')\n",
    "\n",
    "pickle_out_demo = open(\"demo_file.pkl\",\"wb\")\n",
    "pickle.dump(demo, pickle_out_demo)\n",
    "pickle_out_demo.close()\n",
    "\n",
    "pickle_in_demo = open(\"demo_file.pkl\",\"rb\")\n",
    "example_demo = pickle.load(pickle_in_demo)\n",
    "print(example_demo)\n",
    "\n",
    "demo.to_pickle(\"demo_file.pkl\")\n",
    "\n",
    "#import pickle file\n",
    "demo = pd.read_pickle(\"demo_file.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge demography and oralhealth by id\n",
    "oral_selected = oral[['id','ohx_status']]\n",
    "demo_merged = pd.merge(demo, oral_selected, on = 'id', how = 'left')\n",
    "\n",
    "#Separated age into two levels: under 20 and above 20\n",
    "demo_merged['under_20'] = np.where(demo_merged['age']<20, \"True\",\"False\")\n",
    "\n",
    "#Separate education into two levels: 'some college/college graduate', 'No college/<20'\n",
    "conditions = [\n",
    "    (demo_merged['education'] == 4.0) | (demo_merged['education'] == 5.0),\n",
    "    (demo_merged['education'] == 1.0) | (demo_merged['education'] == 2.0) | (demo_merged['education'] == 3.0)]\n",
    "choices = ['some college/college graduate', 'No college/<20']\n",
    "demo_merged['college'] = np.select(conditions, choices, 'No college/<20')\n",
    "demo_updated = demo_merged[['id','gender','age','under_20','college','exam_status','ohx_status']]\n",
    "\n",
    "#Separate ohx into two levels: completing and missing\n",
    "demo_updated['ohx'] = np.where((demo_updated['exam_status'] == 2.0)&(demo_updated['ohx_status'] ==1),'complete','missing')\n",
    "\n",
    "#Replace categorical expression of gender\n",
    "demo_updated['gender'] = np.where(demo_updated['gender'] == 1.0, 'Male', 'Female')\n",
    "demo_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only the exam_status == 2\n",
    "demo_updated_ = demo_updated[demo_updated['exam_status'] == 2.0] \n",
    "\n",
    "#Compute the difference with previous data length and current data length\n",
    "remains = demo_updated_['exam_status'].shape[0]\n",
    "origins = demo_updated['exam_status'].shape[0]\n",
    "diff = origins - remains\n",
    "\n",
    "#Express through dictionary and dataFrame\n",
    "data = {'rows_initial':origins, 'rows_remains':remains,'rows_removed':diff}\n",
    "df = pd.DataFrame(data, index = ['num'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the count and percentage within categorical variable\n",
    "summary = demo_updated_[['age','under_20','gender','college','ohx']]\n",
    "summary['under_20'] = np.where(summary['under_20'] == 'False','above_20','under_20')\n",
    "under_20_sum1 = pd.crosstab(summary['under_20'], summary['ohx'])\n",
    "under_20_sum2 = pd.crosstab(summary['under_20'], summary['ohx'], normalize = 'index')\n",
    "under_20 = (pd.concat([under_20_sum1, under_20_sum2], axis=1, keys=['count', 'pct%'])\n",
    "      .swaplevel(axis=1)\n",
    "      .sort_index(axis=1, ascending=[True, False])\n",
    ")\n",
    "gender_sum1 = pd.crosstab(summary['gender'], summary['ohx'])\n",
    "gender_sum2 = pd.crosstab(summary['gender'], summary['ohx'], normalize = 'index')\n",
    "gender = (pd.concat([gender_sum1, gender_sum2], axis=1, keys=['count', 'pct%'])\n",
    "      .swaplevel(axis=1)\n",
    "      .sort_index(axis=1, ascending=[True, False])\n",
    ")\n",
    "college_sum1 = pd.crosstab(summary['college'], summary['ohx'])\n",
    "college_sum2 = pd.crosstab(summary['college'], summary['ohx'], normalize = 'index')\n",
    "college = (pd.concat([college_sum1, college_sum2], axis=1, keys=['count', 'pct%'])\n",
    "      .swaplevel(axis=1)\n",
    "      .sort_index(axis=1, ascending=[True, False])\n",
    ")\n",
    "summ = pd.concat([under_20,gender,college])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the mean and standard deviation within the continuous variable\n",
    "age = summary.groupby('ohx').agg({'age': ['mean', 'std']}).transpose().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply t-test towards age variable\n",
    "ttest_ind_from_stats(mean1=age['complete'][0], std1=age['complete'][1], nobs1=13,\n",
    "                     mean2=age['missing'][0], std2=age['missing'][1], nobs2=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply chi-square towards under_20 categorical variables\n",
    "under_20_data = np.array([under_20.iloc[0][0:5].values,\n",
    "                  under_20.iloc[1][0:5].values])\n",
    "chi_20 = stats.chi2_contingency(under_20_data)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply chi-square towards college categorical variables\n",
    "college_data = np.array([college.iloc[0][0:5].values,\n",
    "                  college.iloc[1][0:5].values])\n",
    "chi_col = stats.chi2_contingency(college_data)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply chi-square towards gender categorical variables\n",
    "gender_data = np.array([gender.iloc[0][0:5].values,\n",
    "                  gender.iloc[1][0:5].values])\n",
    "chi_gen = stats.chi2_contingency(gender_data)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Table\n",
    "chi_data = {'under_20':chi_20, 'college':chi_col, 'gender':chi_gen}\n",
    "chi_square = pd.DataFrame(chi_data, index = ['statistical_value', 'p-value', 'df'])\n",
    "chi_square.iloc[:1] = chi_square.iloc[:1].applymap('{0:.2f}'.format)\n",
    "chi_square"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
